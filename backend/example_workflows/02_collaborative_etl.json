{
  "name": "Collaborative ETL Pipeline",
  "status": "active",
  "metadata": {
    "description": "An ETL pipeline where nodes communicate to validate and transform data collaboratively",
    "tags": ["demo", "etl", "data-processing", "collaboration"],
    "author": "ChasmX Team",
    "version": "1.0"
  },
  "nodes": [
    {
      "id": "start",
      "type": "start",
      "position": {"x": 50, "y": 250},
      "config": {}
    },
    {
      "id": "extractor",
      "type": "ai-processor",
      "position": {"x": 250, "y": 250},
      "config": {
        "name": "Data Extractor",
        "description": "Extracts and parses raw data from various sources",
        "system_prompt": "You are a data extraction specialist. You parse raw data and prepare it for transformation. Always validate with the transformer before proceeding.",
        "prompt": "Extract customer data from input: {{input}}. After extraction, ask the transformer node to validate the schema using: CALL: ask_node('transformer', 'Can you validate this data schema: [extracted data structure]?')",
        "can_communicate": true,
        "model": "google/gemini-2.0-flash-exp:free",
        "temperature": 0.3,
        "max_tokens": 2048
      }
    },
    {
      "id": "transformer",
      "type": "ai-processor",
      "position": {"x": 550, "y": 250},
      "config": {
        "name": "Data Transformer",
        "description": "Transforms and validates data structure",
        "system_prompt": "You are a data transformation specialist. You validate schemas, transform data formats, and ensure data quality. Coordinate with the loader to understand target requirements.",
        "prompt": "Transform and validate data from extractor. Check with loader about target format using: CALL: ask_node('loader', 'What format do you need for the customer data?'). Store the transformation rules in shared context using: CALL: set_shared_context('transform_rules', 'your_rules_here')",
        "can_communicate": true,
        "model": "google/gemini-2.0-flash-exp:free",
        "temperature": 0.3,
        "max_tokens": 2048
      }
    },
    {
      "id": "loader",
      "type": "ai-processor",
      "position": {"x": 850, "y": 250},
      "config": {
        "name": "Data Loader",
        "description": "Loads validated data into target system",
        "system_prompt": "You are a data loading specialist. You validate final data quality and load it into the target system. If you find issues, ask the transformer to fix them.",
        "prompt": "Validate and prepare to load the transformed data. If there are any data quality issues, ask the transformer to fix them using: CALL: ask_node('transformer', 'Found issue: [describe issue]. Can you fix this?'). Otherwise, broadcast success using: CALL: broadcast_message('Data successfully loaded to target system')",
        "can_communicate": true,
        "model": "google/gemini-2.0-flash-exp:free",
        "temperature": 0.3,
        "max_tokens": 2048
      }
    },
    {
      "id": "end",
      "type": "end",
      "position": {"x": 1100, "y": 250},
      "config": {}
    }
  ],
  "edges": [
    {"from": "start", "to": "extractor"},
    {"from": "extractor", "to": "transformer"},
    {"from": "transformer", "to": "loader"},
    {"from": "loader", "to": "end"}
  ],
  "variables": [
    {
      "id": "input_data",
      "name": "input",
      "value": "{\"customers\": [{\"name\": \"John Doe\", \"email\": \"john@example.com\", \"age\": 30}]}",
      "type": "string",
      "description": "Raw input data to process",
      "scope": "workflow"
    }
  ]
}
